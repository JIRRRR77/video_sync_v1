{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba03dbf",
   "metadata": {},
   "source": [
    "## MultiHeadAttention using attention matrix for delay estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ca5cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models, regularizers\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "732d8443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_features: (1, 20, 48)\n"
     ]
    }
   ],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self, type=\"flows\", l2_reg=0.01):\n",
    "        super(CNN, self).__init__()\n",
    "        self.type = type\n",
    "        if type == \"images_flows\":\n",
    "            dim = 6\n",
    "        elif type == \"cross_flows\":\n",
    "            dim = 9\n",
    "        else:\n",
    "            dim = 3\n",
    "        self.cnn = models.Sequential()\n",
    "\n",
    "        reg = regularizers.l2(l2_reg)\n",
    "\n",
    "        self.cnn.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, dim), kernel_regularizer=reg))\n",
    "        self.cnn.add(layers.MaxPooling2D((3, 3)))\n",
    "\n",
    "        self.cnn.add(layers.Conv2D(48, (3, 3), activation='relu', kernel_regularizer=reg))\n",
    "        self.cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        self.cnn.add(layers.Conv2D(48, (3, 3), activation='relu', kernel_regularizer=reg))\n",
    "        self.cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        self.cnn.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=reg))\n",
    "        self.cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        self.cnn.add(layers.GlobalAveragePooling2D())\n",
    "        self.cnn.add(layers.Dense(48, activation='relu', kernel_regularizer=reg))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.cnn(inputs)\n",
    "    \n",
    "Extractor = CNN()\n",
    "\n",
    "random_images = np.random.random((20, 224, 224, 3)) * 255\n",
    "random_images = random_images.astype('float32')/ 255.0\n",
    "left_imgs = tf.convert_to_tensor(random_images, dtype=tf.float32)\n",
    "\n",
    "random_images = np.random.random((20, 224, 224, 3)) * 255\n",
    "random_images = random_images.astype('float32')/ 255.0\n",
    "right_imgs = tf.convert_to_tensor(random_images, dtype=tf.float32)\n",
    "\n",
    "left_features = Extractor(left_imgs)\n",
    "right_features = Extractor(right_imgs)\n",
    "left_features = tf.expand_dims(left_features,axis=0)  #[batch_size, query_seq_length, feature_dim]\n",
    "right_features = tf.expand_dims(right_features,axis=0) # [batch_size, key_seq_length, feature_dim]\n",
    "\n",
    "print(\"left_features:\",left_features.shape) #(1, 20, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "326f9aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 20, 20)\n",
      "(1, 20, 20)\n",
      "-17\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "\n",
    "query, key, value = left_features, right_features, right_features\n",
    "attention_layer = MultiHeadAttention(num_heads=8, key_dim=64)\n",
    "output, attention_scores = attention_layer(query, key, value, return_attention_scores=True)\n",
    "similarity_matrix = tf.reduce_mean(attention_scores, axis=1)\n",
    "\n",
    "print(attention_scores.shape)   # (1, 8, 20, 20)\n",
    "print(similarity_matrix.shape)  # (1, 20, 20)\n",
    "\n",
    "matrix = similarity_matrix[0]\n",
    "\n",
    "# Calculate the mean of the diagonals and find the diagonal with the maximum mean\n",
    "diagonal_means = []\n",
    "for offset in range(-19, 20):\n",
    "    diagonal = np.diagonal(matrix, offset=offset)\n",
    "    if diagonal.size > 0:\n",
    "        mean_value = np.mean(diagonal)\n",
    "        diagonal_means.append((offset, mean_value))\n",
    "\n",
    "# Find the diagonal with the maximum mean\n",
    "max_mean = max(diagonal_means, key=lambda x: x[1])\n",
    "max_offset, _ = max_mean\n",
    "\n",
    "print(max_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "250b0793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(matrix, annot=False, cmap='coolwarm', cbar=True)\n",
    "\n",
    "# Define the style for the yellow box\n",
    "box_color = 'yellow'\n",
    "box_linewidth = 4\n",
    "\n",
    "# Add a yellow box to highlight the diagonal with the maximum mean\n",
    "if max_offset >= 0:\n",
    "    for i in range(min(20 - max_offset, 20)):\n",
    "        ax.add_patch(Rectangle((i, i + max_offset), 1, 1, fill=False, edgecolor=box_color, lw=box_linewidth))\n",
    "else:\n",
    "    for i in range(min(20, 20 + max_offset)):\n",
    "        ax.add_patch(Rectangle((i - max_offset, i), 1, 1, fill=False, edgecolor=box_color, lw=box_linewidth))\n",
    "\n",
    "plt.title('20x20 Similarity Matrix with Highlighted Diagonal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53147fcd",
   "metadata": {},
   "source": [
    "## Seem like if the output is attention_scores,the gradient can not be back propagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5ef7fe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_100 (InputLayer)         [(None, 20, 64)]     0           []                               \n",
      "                                                                                                  \n",
      " input_101 (InputLayer)         [(None, 20, 64)]     0           []                               \n",
      "                                                                                                  \n",
      " input_102 (InputLayer)         [(None, 20, 64)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_79 (Multi  ((None, 20, 64),    132672      ['input_100[0][0]',              \n",
      " HeadAttention)                  (None, 8, 20, 20))               'input_101[0][0]',              \n",
      "                                                                  'input_102[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 132,672\n",
      "Trainable params: 132,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['multi_head_attention_79/value/kernel:0', 'multi_head_attention_79/value/bias:0', 'multi_head_attention_79/attention_output/kernel:0', 'multi_head_attention_79/attention_output/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['multi_head_attention_79/value/kernel:0', 'multi_head_attention_79/value/bias:0', 'multi_head_attention_79/attention_output/kernel:0', 'multi_head_attention_79/attention_output/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "1/1 [==============================] - 1s 1s/step - loss: 811.7873\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 811.7873\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 811.7873\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 811.7873\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 811.7873\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 811.7872\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 811.7873\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 811.7873\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 811.7873\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 811.7874\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "class MultiHeadAttentionModel:\n",
    "    def __init__(self, num_heads, key_dim, sequence_length, input_dim):\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        query_input = Input(shape=(self.sequence_length, self.input_dim))\n",
    "        key_input = Input(shape=(self.sequence_length, self.input_dim))\n",
    "        value_input = Input(shape=(self.sequence_length, self.input_dim))\n",
    "\n",
    "        # MultiHeadAttention\n",
    "        attention_layer = MultiHeadAttention(num_heads=self.num_heads, key_dim=self.key_dim)\n",
    "        attention_output, attention_scores = attention_layer(query=query_input, key=key_input, value=value_input, return_attention_scores=True)\n",
    "\n",
    "        model = Model(inputs=[query_input, key_input, value_input], outputs=attention_scores)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def compile_model(self, optimizer='adam'):\n",
    "        self.model.compile(optimizer=optimizer, loss=self.loss_diagonal)\n",
    "    \n",
    "#     def loss(self, y_true, attention_scores):\n",
    "#         return tf.reduce_mean(tf.square(y_true - attention_scores))\n",
    "    \n",
    "    def loss_diagonal(self, y_true, attention_scores):\n",
    "        similarity_matrix = tf.reduce_mean(attention_scores, axis=1)\n",
    "\n",
    "        def calculate_max_offset(matrix):\n",
    "            diagonal_means = []\n",
    "            for offset in range(-self.sequence_length + 1, self.sequence_length):\n",
    "                diagonal = tf.linalg.diag_part(matrix, k=offset)\n",
    "                mean_value = tf.cond(tf.size(diagonal) > 0, lambda: tf.reduce_mean(diagonal), lambda: tf.constant(0.0))\n",
    "                diagonal_means.append(mean_value)\n",
    "            diagonal_means = tf.stack(diagonal_means)\n",
    "            max_offset = tf.argmax(diagonal_means)\n",
    "            return tf.cast(max_offset, tf.float32)\n",
    "\n",
    "        max_offsets = tf.map_fn(calculate_max_offset, similarity_matrix, fn_output_signature=tf.float32)\n",
    "\n",
    "        return tf.reduce_mean(tf.square(y_true - max_offsets))\n",
    "        \n",
    "    def train_model(self, X_train, y_train, epochs=10, batch_size=32):\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_heads = 8\n",
    "    key_dim = 64\n",
    "    sequence_length = 20\n",
    "    input_dim = 48\n",
    "\n",
    "    mha_model = MultiHeadAttentionModel(num_heads, key_dim, sequence_length, input_dim)\n",
    "    mha_model.compile_model()\n",
    "\n",
    "    mha_model.summary()\n",
    "\n",
    "    query_data = np.random.random((32, sequence_length, input_dim))\n",
    "    key_data = np.random.random((32, sequence_length, input_dim))\n",
    "    value_data = key_data\n",
    "    y_train = np.random.random((32,))\n",
    "#     y_train = np.random.random((32,8,20,20))\n",
    "\n",
    "    X_train = [query_data, key_data, value_data]\n",
    "    mha_model.train_model(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57ac6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 19:42:44.037221: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-12 19:42:44.893861: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-12 19:42:46.397537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64:/usr/include/opencv4\n",
      "2024-08-12 19:42:46.397661: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64:/usr/include/opencv4\n",
      "2024-08-12 19:42:46.397669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-08-12 19:42:49.244834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-12 19:42:49.346528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-12 19:42:49.347259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-12 19:42:49.350837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-12 19:42:49.353865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-12 19:42:49.354559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-12 19:42:49.355169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-12 19:42:50.679565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-12 19:42:50.680586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-12 19:42:50.680795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-12 19:42:50.680960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2578 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_multi_head_attention/value/kernel:0', 'custom_multi_head_attention/value/bias:0', 'custom_multi_head_attention/attention_output/kernel:0', 'custom_multi_head_attention/attention_output/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_multi_head_attention/value/kernel:0', 'custom_multi_head_attention/value/bias:0', 'custom_multi_head_attention/attention_output/kernel:0', 'custom_multi_head_attention/attention_output/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "10/10 [==============================] - 2s 3ms/step - loss: 4.0058\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.0250\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 4.1764\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.7556\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 6.0872\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 8.4882\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12.0002\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 16.5257\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 21.9373\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 28.4991\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Custom MultiHeadAttention layer that only returns attention_scores\n",
    "class CustomMultiHeadAttention(MultiHeadAttention):\n",
    "    def call(self, query, value, key=None, attention_mask=None, **kwargs):\n",
    "        # Call the original MultiHeadAttention call function\n",
    "        _, attention_scores = super().call(\n",
    "            query=query,\n",
    "            value=value,\n",
    "            key=key,\n",
    "            attention_mask=attention_mask,\n",
    "            return_attention_scores=True,  # Ensure to return attention_scores\n",
    "            **kwargs\n",
    "        )\n",
    "        return attention_scores  # Return only the attention_scores\n",
    "\n",
    "# Build the model\n",
    "input_layer = Input(shape=(5, 64))\n",
    "attention_scores = CustomMultiHeadAttention(num_heads=8, key_dim=64)(input_layer, input_layer)\n",
    "model = Model(inputs=input_layer, outputs=attention_scores)\n",
    "\n",
    "# Compile the model using categorical_crossentropy as the loss function, suitable for probability distribution outputs\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Generate random data as input and target output\n",
    "x_train = np.random.random((100, 5, 64))\n",
    "y_train = np.random.random((100, 8, 5, 5))  # Note: y_train shape should match the expected output shape from the model\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=10)\n",
    "\n",
    "# Use GradientTape to check gradient flow\n",
    "with tf.GradientTape() as tape:\n",
    "    inputs = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "    tape.watch(inputs)\n",
    "    predictions = model(inputs)\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_train, predictions)\n",
    "\n",
    "# gradients = tape.gradient(loss, model.trainable_variables)\n",
    "# print(\"Gradients on trainable variables:\", gradients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4cec8",
   "metadata": {},
   "source": [
    "## MultiHeadAttention predicting delay token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ed843bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim:  3\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 5ms/step - loss: 3.3770 - accuracy: 0.9000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8023 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.6385e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a485b5ad0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers, losses\n",
    "import numpy as np\n",
    "\n",
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self, type=\"flows\", l2_reg=0.01):\n",
    "        super(CNN, self).__init__()\n",
    "        self.type = type\n",
    "        if type == \"images_flows\":\n",
    "            dim = 6\n",
    "        elif type == \"cross_flows\":\n",
    "            dim = 9\n",
    "        else:\n",
    "            dim = 3\n",
    "        print(\"dim: \", dim)\n",
    "        self.cnn = models.Sequential()\n",
    "\n",
    "        reg = regularizers.l2(l2_reg)\n",
    "\n",
    "        self.cnn.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, dim), kernel_regularizer=reg))\n",
    "        self.cnn.add(layers.MaxPooling2D((3, 3)))\n",
    "\n",
    "        self.cnn.add(layers.Conv2D(48, (3, 3), activation='relu', kernel_regularizer=reg))\n",
    "        self.cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        self.cnn.add(layers.Conv2D(48, (3, 3), activation='relu', kernel_regularizer=reg))\n",
    "        self.cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        self.cnn.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=reg))\n",
    "        self.cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        self.cnn.add(layers.GlobalAveragePooling2D())\n",
    "        self.cnn.add(layers.Dense(48, activation='relu', kernel_regularizer=reg))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.cnn(inputs)\n",
    "\n",
    "class MLPHead(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, num_classes, dropout_rate=0.1):\n",
    "        super(MLPHead, self).__init__()\n",
    "        self.dense1 = layers.Dense(hidden_dim, activation='relu')\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.dense2 = layers.Dense(num_classes)\n",
    "        self.softmax = layers.Softmax()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "class TransformerModel(tf.keras.Model):\n",
    "    def __init__(self, num_heads, dff, num_layers, hidden_dim, num_classes, rate=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.class_token = self.add_weight(\"class_token\", shape=[1, 1, 48], initializer=\"random_normal\")\n",
    "        self.encoder_layers = [layers.MultiHeadAttention(num_heads=num_heads, key_dim=48) for _ in range(num_layers)]\n",
    "        self.ffn_layers = [self.point_wise_feed_forward_network(48, dff) for _ in range(num_layers)]\n",
    "        self.dropout_layers = [layers.Dropout(rate) for _ in range(num_layers)]\n",
    "        self.mlp_head = MLPHead(hidden_dim, num_classes, dropout_rate=rate)\n",
    "\n",
    "    def point_wise_feed_forward_network(self, d_model, dff):\n",
    "        return tf.keras.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        query = inputs['query']\n",
    "        context = inputs['context']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        class_token = tf.broadcast_to(self.class_token, [batch_size, 1, 48])\n",
    "        for i in range(self.num_layers):\n",
    "            class_token = self.encoder_layers[i](query=class_token, value=context, key=context)\n",
    "            class_token = self.ffn_layers[i](class_token)\n",
    "            class_token = self.dropout_layers[i](class_token, training=training)\n",
    "        class_token_output = tf.squeeze(class_token, axis=1)  # Remove the sequence dimension\n",
    "        output = self.mlp_head(class_token_output, training=training)\n",
    "        return output\n",
    "\n",
    "# Instantiate the CNN model\n",
    "Extractor = CNN()\n",
    "\n",
    "# Generate random images\n",
    "random_images = np.random.random((20, 224, 224, 3)) * 255\n",
    "random_images = random_images.astype('float32') / 255.0\n",
    "left_imgs = tf.convert_to_tensor(random_images, dtype=tf.float32)\n",
    "\n",
    "random_images = np.random.random((20, 224, 224, 3)) * 255\n",
    "random_images = random_images.astype('float32') / 255.0\n",
    "right_imgs = tf.convert_to_tensor(random_images, dtype=tf.float32)\n",
    "\n",
    "# Extract features\n",
    "left_features = Extractor(left_imgs)\n",
    "right_features = Extractor(right_imgs)\n",
    "\n",
    "# Reshape features to [num_samples, seq_length, feature_dim]\n",
    "left_features = tf.reshape(left_features, [1, 20, 48])\n",
    "right_features = tf.reshape(right_features, [1, 20, 48])\n",
    "\n",
    "# Prepare dummy labels for training\n",
    "num_classes = 40\n",
    "dummy_labels = tf.random.uniform([1], maxval=num_classes, dtype=tf.int32)  # Single random label\n",
    "\n",
    "# Define the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({'query': left_features, 'context': right_features}, dummy_labels))\n",
    "dataset = dataset.repeat().batch(1)  # Repeat dataset for training and batch size of 1\n",
    "\n",
    "# Instantiate the Transformer model\n",
    "hidden_dim = 512  # Example hidden dimension for MLP head\n",
    "transformer = TransformerModel(num_heads=8, dff=128, num_layers=2, hidden_dim=hidden_dim, num_classes=num_classes)\n",
    "\n",
    "# Define loss function, optimizer, and metrics\n",
    "loss_fn = losses.SparseCategoricalCrossentropy()\n",
    "optimizer = optimizers.Adam()\n",
    "\n",
    "# Compile the model\n",
    "transformer.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "transformer.fit(dataset, steps_per_epoch=10, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fb198d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " multi_head_attention_56 (Mu  multiple                 74928     \n",
      " ltiHeadAttention)                                               \n",
      "                                                                 \n",
      " multi_head_attention_57 (Mu  multiple                 74928     \n",
      " ltiHeadAttention)                                               \n",
      "                                                                 \n",
      " sequential_58 (Sequential)  (None, 1, 48)             12464     \n",
      "                                                                 \n",
      " sequential_59 (Sequential)  (None, 1, 48)             12464     \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " mlp_head_28 (MLPHead)       multiple                  45608     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220,440\n",
      "Trainable params: 220,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b18f0c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 56.6057 - accuracy: 0.0000e+00\n",
      "Test Loss: 56.60567855834961\n",
      "Test Accuracy: 0.0\n",
      "(100, 48)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[8.7303086e-24 7.5729631e-25 1.7103794e-25 2.8701448e-24 4.6874052e-24\n",
      " 4.4761795e-26 1.9642023e-24 3.7596297e-25 1.9204243e-22 4.6879523e-27\n",
      " 2.6765143e-24 9.7083155e-24 2.8278255e-24 2.5260622e-24 6.4930039e-27\n",
      " 2.8680530e-25 1.2352159e-24 6.6704871e-24 1.0655454e-25 2.7292507e-25\n",
      " 1.5143536e-24 1.2450232e-23 5.3253571e-26 1.5185369e-23 2.6037452e-23\n",
      " 1.0000000e+00 7.3104031e-25 4.6439576e-25 8.1066434e-26 5.5899847e-25\n",
      " 5.5556121e-24 1.1635327e-26 2.4411495e-27 2.2637604e-24 1.5466726e-26\n",
      " 3.5405036e-26 2.5290222e-24 1.0497220e-25 1.7972824e-25 2.4954520e-24]\n"
     ]
    }
   ],
   "source": [
    "# Prepare dummy data for testing\n",
    "test_random_images = np.random.random((20, 224, 224, 3)) * 255\n",
    "test_random_images = test_random_images.astype('float32') / 255.0\n",
    "test_left_imgs = tf.convert_to_tensor(test_random_images, dtype=tf.float32)\n",
    "\n",
    "test_random_images = np.random.random((20, 224, 224, 3)) * 255\n",
    "test_random_images = test_random_images.astype('float32') / 255.0\n",
    "test_right_imgs = tf.convert_to_tensor(test_random_images, dtype=tf.float32)\n",
    "\n",
    "# Extract features for testing\n",
    "test_left_features = Extractor(test_left_imgs)\n",
    "test_right_features = Extractor(test_right_imgs)\n",
    "\n",
    "# Reshape test features to [num_samples, seq_length, feature_dim]\n",
    "test_left_features = tf.reshape(test_left_features, [1, 20, 48])\n",
    "test_right_features = tf.reshape(test_right_features, [1, 20, 48])\n",
    "\n",
    "# Prepare dummy labels for testing\n",
    "test_dummy_labels = tf.random.uniform([1], maxval=num_classes, dtype=tf.int32)  # Single random label\n",
    "\n",
    "# Define the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({'query': test_left_features, 'context': test_right_features}, test_dummy_labels))\n",
    "test_dataset = test_dataset.batch(1)  # Batch size of 1 for testing\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = transformer.evaluate(test_dataset)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Predict new data\n",
    "num_new_samples = 5\n",
    "new_random_images = np.random.random((num_new_samples*20, 224, 224, 3)) * 255\n",
    "new_random_images = new_random_images.astype('float32') / 255.0\n",
    "new_left_imgs = tf.convert_to_tensor(new_random_images, dtype=tf.float32)\n",
    "\n",
    "new_random_images = np.random.random((num_new_samples*20, 224, 224, 3)) * 255\n",
    "new_random_images = new_random_images.astype('float32') / 255.0\n",
    "new_right_imgs = tf.convert_to_tensor(new_random_images, dtype=tf.float32)\n",
    "\n",
    "# Extract features for new data\n",
    "new_left_features = Extractor(new_left_imgs)\n",
    "new_right_features = Extractor(new_right_imgs)\n",
    "print(new_left_features.shape)\n",
    "\n",
    "# Reshape new features to [num_samples, seq_length, feature_dim]\n",
    "new_left_features = tf.reshape(new_left_features, [num_new_samples, 20, 48])\n",
    "new_right_features = tf.reshape(new_right_features, [num_new_samples, 20, 48])\n",
    "\n",
    "# Predict new data\n",
    "predictions = transformer.predict({'query': new_left_features, 'context': new_right_features})\n",
    "print(predictions[0])\n",
    "# predicted_classes = tf.argmax(predictions, axis=-1)\n",
    "# print(f'Predicted classes: {predicted_classes.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fade155",
   "metadata": {},
   "source": [
    "## Training in real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77495d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.69037163, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.0563793, 0.0, 0.0, 0.0, 0.8...</td>\n",
       "      <td>1963</td>\n",
       "      <td>1983</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.8872391, 0.0, 0.0, 0.0, 1.2...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.37041047, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>8545</td>\n",
       "      <td>8554</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.340517, 0.0, 0.0, 0.0, 0.64...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.8816519, 0.0, 0.0, 0.0, 0.4...</td>\n",
       "      <td>2322</td>\n",
       "      <td>2326</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3974726...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.16040325, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>7385</td>\n",
       "      <td>7398</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.4631886, 0.0, 0.0, 0.0, 0.4...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.233583, 0.0, 0.0, 0.0, 0.16...</td>\n",
       "      <td>7953</td>\n",
       "      <td>7941</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.69037163, 0.0, 0.0, 0.0, 0....   \n",
       "1  [[0.0, 0.0, 0.0, 0.8872391, 0.0, 0.0, 0.0, 1.2...   \n",
       "2  [[0.0, 0.0, 0.0, 1.340517, 0.0, 0.0, 0.0, 0.64...   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3974726...   \n",
       "4  [[0.0, 0.0, 0.0, 1.4631886, 0.0, 0.0, 0.0, 0.4...   \n",
       "\n",
       "                                                   1     2     3    4  \n",
       "0  [[0.0, 0.0, 0.0, 1.0563793, 0.0, 0.0, 0.0, 0.8...  1963  1983   20  \n",
       "1  [[0.0, 0.0, 0.0, 0.37041047, 0.0, 0.0, 0.0, 0....  8545  8554    9  \n",
       "2  [[0.0, 0.0, 0.0, 1.8816519, 0.0, 0.0, 0.0, 0.4...  2322  2326    4  \n",
       "3  [[0.0, 0.0, 0.0, 0.16040325, 0.0, 0.0, 0.0, 0....  7385  7398   13  \n",
       "4  [[0.0, 0.0, 0.0, 1.233583, 0.0, 0.0, 0.0, 0.16...  7953  7941  -12  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# extracted feature\n",
    "trainDS = np.load(\"/home/jireh/MT/video_sync_v1/trash/featureData.npy\",allow_pickle=True)\n",
    "print(trainDS[0][0].shape)\n",
    "\n",
    "# Convert to a pandas DataFrame (optional, for better visualization)\n",
    "df = pd.DataFrame(trainDS)\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f4a4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "class MLPHead(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_dim, num_classes, dropout_rate=0.1):\n",
    "        super(MLPHead, self).__init__()\n",
    "        self.dense1 = layers.Dense(hidden_dim, activation='relu')\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.dense2 = layers.Dense(num_classes)\n",
    "        self.softmax = layers.Softmax()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "class TransformerModel(tf.keras.Model):\n",
    "    def __init__(self, num_heads, dff, num_layers, hidden_dim, num_classes, rate=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.class_token = self.add_weight(\"class_token\", shape=[1, 1, 48], initializer=\"random_normal\")\n",
    "        self.encoder_layers = [layers.MultiHeadAttention(num_heads=num_heads, key_dim=48) for _ in range(num_layers)]\n",
    "        self.ffn_layers = [self.point_wise_feed_forward_network(48, dff) for _ in range(num_layers)]\n",
    "        self.dropout_layers = [layers.Dropout(rate) for _ in range(num_layers)]\n",
    "        self.mlp_head = MLPHead(hidden_dim, num_classes, dropout_rate=rate)\n",
    "\n",
    "    def point_wise_feed_forward_network(self, d_model, dff):\n",
    "        return tf.keras.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        query = inputs['query']\n",
    "        context = inputs['context']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        class_token = tf.broadcast_to(self.class_token, [batch_size, 1, 48])\n",
    "        for i in range(self.num_layers):\n",
    "            class_token = self.encoder_layers[i](query=class_token, value=context, key=context)\n",
    "            class_token = self.ffn_layers[i](class_token)\n",
    "            class_token = self.dropout_layers[i](class_token, training=training)\n",
    "        class_token_output = tf.squeeze(class_token, axis=1)  # Remove the sequence dimension\n",
    "        output = self.mlp_head(class_token_output, training=training)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c912fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 11ms/step - loss: 3.6896 - accuracy: 0.0273\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 3.6895 - accuracy: 0.0238\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.6894 - accuracy: 0.0277\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.6897 - accuracy: 0.0191\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.6899 - accuracy: 0.0285\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.6896 - accuracy: 0.0227\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.6894 - accuracy: 0.0227\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.6901 - accuracy: 0.0223\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.6891 - accuracy: 0.0223\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 3.6898 - accuracy: 0.0230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a492b1310>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_features = trainDS[:, 0].tolist()\n",
    "right_features = trainDS[:, 1].tolist()\n",
    "y = trainDS[:, 4].tolist()\n",
    "\n",
    "left_features = np.array(left_features)\n",
    "right_features = np.array(right_features)\n",
    "y = np.array(y)\n",
    "\n",
    "left_features = tf.convert_to_tensor(left_features, dtype=tf.float32)\n",
    "right_features = tf.convert_to_tensor(right_features, dtype=tf.float32)\n",
    "y = to_categorical(y,num_classes=40)\n",
    "\n",
    "size = int(len(y) * 0.8)  # 80% of the data for training\n",
    "\n",
    "# left_features_train, left_features_val = left_features[:size], left_features[size:]\n",
    "# right_features_train, right_features_val = right_features[:size], right_features[size:]\n",
    "# y_train, y_val = y[:size], y[size:]\n",
    "\n",
    "# Define the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({'query': left_features, 'context': right_features}, y))\n",
    "dataset = dataset.repeat().batch(256)  \n",
    "\n",
    "# Instantiate the Transformer model\n",
    "hidden_dim = 512  # Example hidden dimension for MLP head\n",
    "transformer = TransformerModel(num_heads=8, dff=128, num_layers=2, hidden_dim=hidden_dim, num_classes=num_classes)\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "# Compile the model\n",
    "transformer.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "transformer.fit(dataset, steps_per_epoch=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5fabc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 08:04:16.991511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-10 08:04:17.588854: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-10 08:04:18.755148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64:/usr/include/opencv4\n",
      "2024-08-10 08:04:18.755286: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64:/usr/include/opencv4\n",
      "2024-08-10 08:04:18.755295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score, mean_absolute_error\n",
    "\n",
    "class TransformerDelay:\n",
    "    def __init__(self, num_heads=8, dff=128, num_layers=2, hidden_dim=512, num_classes=40, rate=0.1):\n",
    "        # Initialize the TransformerDelay class with default or custom parameters\n",
    "        self.model = self.build_model(num_heads, dff, num_layers, hidden_dim, num_classes, rate)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), metrics=['accuracy'])\n",
    "\n",
    "    def build_model(self, num_heads, dff, num_layers, hidden_dim, num_classes, rate):\n",
    "        # Inner class to define the MLP Head\n",
    "        class MLPHead(tf.keras.layers.Layer):\n",
    "            def __init__(self, hidden_dim, num_classes, dropout_rate=0.1):\n",
    "                super(MLPHead, self).__init__()\n",
    "                self.dense1 = layers.Dense(hidden_dim, activation='relu')\n",
    "                self.dropout = layers.Dropout(dropout_rate)\n",
    "                self.dense2 = layers.Dense(num_classes)\n",
    "                self.softmax = layers.Softmax()\n",
    "\n",
    "            def call(self, inputs, training=False):\n",
    "                # Define the forward pass for the MLP Head\n",
    "                x = self.dense1(inputs)\n",
    "                x = self.dropout(x, training=training)\n",
    "                x = self.dense2(x)\n",
    "                return self.softmax(x)\n",
    "\n",
    "        # Inner class to define the Transformer Model\n",
    "        class TransformerModel(tf.keras.Model):\n",
    "            def __init__(self, num_heads, dff, num_layers, hidden_dim, num_classes, rate=0.1):\n",
    "                super(TransformerModel, self).__init__()\n",
    "                self.num_layers = num_layers\n",
    "                self.class_token = self.add_weight(\"class_token\", shape=[1, 1, 48], initializer=\"random_normal\")\n",
    "                self.encoder_layers = [layers.MultiHeadAttention(num_heads=num_heads, key_dim=48) for _ in range(num_layers)]\n",
    "                self.ffn_layers = [self.point_wise_feed_forward_network(48, dff) for _ in range(num_layers)]\n",
    "                self.dropout_layers = [layers.Dropout(rate) for _ in range(num_layers)]\n",
    "                self.mlp_head = MLPHead(hidden_dim, num_classes, dropout_rate=rate)\n",
    "\n",
    "            def point_wise_feed_forward_network(self, d_model, dff):\n",
    "                # Define the point-wise feed forward network used in the Transformer layers\n",
    "                return tf.keras.Sequential([\n",
    "                    layers.Dense(dff, activation='relu'),\n",
    "                    layers.Dense(d_model)\n",
    "                ])\n",
    "\n",
    "            def call(self, inputs, training=True):\n",
    "                # Define the forward pass for the Transformer Model\n",
    "                query = inputs['query']\n",
    "                context = inputs['context']\n",
    "                batch_size = tf.shape(query)[0]\n",
    "                class_token = tf.broadcast_to(self.class_token, [batch_size, 1, 48])\n",
    "                for i in range(self.num_layers):\n",
    "                    class_token = self.encoder_layers[i](query=class_token, value=context, key=context)\n",
    "                    class_token = self.ffn_layers[i](class_token)\n",
    "                    class_token = self.dropout_layers[i](class_token, training=training)\n",
    "                class_token_output = tf.squeeze(class_token, axis=1)\n",
    "                output = self.mlp_head(class_token_output, training=training)\n",
    "                return output\n",
    "\n",
    "        # Return the built TransformerModel\n",
    "        return TransformerModel(num_heads, dff, num_layers, hidden_dim, num_classes, rate)\n",
    "\n",
    "    def train(self, pathSimilarityVectorsArray: str, loadweight=\"\", model_name=\"\"):\n",
    "        # Load the training dataset\n",
    "        trainDS = np.load(fr\"{pathSimilarityVectorsArray}\", allow_pickle=True)\n",
    "        left_features = trainDS[:, 0].tolist()\n",
    "        right_features = trainDS[:, 1].tolist()\n",
    "        y = trainDS[:, 4].tolist()\n",
    "\n",
    "        # Convert data to the appropriate format\n",
    "        left_features = np.array(left_features)\n",
    "        right_features = np.array(right_features)\n",
    "        y = np.array(y)\n",
    "\n",
    "        left_features = tf.convert_to_tensor(left_features, dtype=tf.float32)\n",
    "        right_features = tf.convert_to_tensor(right_features, dtype=tf.float32)\n",
    "        y = to_categorical(y, num_classes=40)\n",
    "\n",
    "        # Split the dataset into training and validation sets\n",
    "        size = int(len(y) * 0.8)\n",
    "        left_features_train, left_features_val = left_features[:size], left_features[size:]\n",
    "        right_features_train, right_features_val = right_features[:size], right_features[size:]\n",
    "        y_train, y_val = y[:size], y[size:]\n",
    "\n",
    "        # Create the TensorFlow dataset for training\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            ({'query': left_features_train, 'context': right_features_train}, y_train)\n",
    "        ).repeat().batch(256)\n",
    "\n",
    "        # Define the directory for saving model weights\n",
    "        weightsPath = fr\"model/TransformerDelay/weight/{model_name}\"\n",
    "        if not os.path.exists(weightsPath):\n",
    "            os.makedirs(weightsPath)\n",
    "\n",
    "        # Define early stopping callback and model checkpoint callback\n",
    "        best_metrics_callback = callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "        checkPoint = callbacks.ModelCheckpoint(\n",
    "            filepath=fr\"{weightsPath}/weights\",\n",
    "            save_weights_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True)\n",
    "\n",
    "        # Load pre-trained weights if provided\n",
    "        if loadweight:\n",
    "            try:\n",
    "                self.loadWeights(loadweight)\n",
    "            except Exception as e:\n",
    "                print(f\"Missing weight file\")\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(dataset, validation_data=({'query': left_features_val, 'context': right_features_val}, y_val),\n",
    "                       callbacks=[checkPoint, best_metrics_callback], steps_per_epoch=10, epochs=200)\n",
    "        self.model.load_weights(fr\"{weightsPath}/weights\")\n",
    "\n",
    "    def loadWeights(self, weightsPath):\n",
    "        # Load model weights from the specified path\n",
    "        self.model.load_weights(weightsPath).expect_partial()\n",
    "\n",
    "    def evaluate(self, pathSimilarityVectorsArray, loadweight=\"\"):\n",
    "        # Load the evaluation dataset\n",
    "        print(fr\"{pathSimilarityVectorsArray}\")\n",
    "        db = np.load(fr\"{pathSimilarityVectorsArray}\", allow_pickle=True)\n",
    "\n",
    "        left_features = db[:, 0].tolist()\n",
    "        right_features = db[:, 1].tolist()\n",
    "        y = db[:, 4].tolist()\n",
    "\n",
    "        # Convert data to the appropriate format\n",
    "        left_features = np.array(left_features)\n",
    "        right_features = np.array(right_features)\n",
    "        y = np.array(y)\n",
    "\n",
    "        left_features = tf.convert_to_tensor(left_features, dtype=tf.float32)\n",
    "        right_features = tf.convert_to_tensor(right_features, dtype=tf.float32)\n",
    "        y = to_categorical(y, num_classes=40)\n",
    "\n",
    "        # Load pre-trained weights if provided\n",
    "        if loadweight:\n",
    "            try:\n",
    "                self.loadWeights(loadweight)\n",
    "            except Exception as e:\n",
    "                print(f\"Missing weight file\")\n",
    "\n",
    "        # Evaluate the model\n",
    "        self.model.evaluate({'query': left_features, 'context': right_features}, y)\n",
    "\n",
    "    def predict(self, pathSimilarityVectorsArray, loadweight=\"\", visualization=False):\n",
    "        # Load the prediction dataset\n",
    "        db = np.load(fr\"{pathSimilarityVectorsArray}\", allow_pickle=True)\n",
    "        left_features = db[:, 0].tolist()\n",
    "        right_features = db[:, 1].tolist()\n",
    "        y = db[:, 4].tolist()\n",
    "\n",
    "        # Convert data to the appropriate format\n",
    "        left_features = np.array(left_features)\n",
    "        right_features = np.array(right_features)\n",
    "\n",
    "        left_features = tf.convert_to_tensor(left_features, dtype=tf.float32)\n",
    "        right_features = tf.convert_to_tensor(right_features, dtype=tf.float32)\n",
    "\n",
    "        # Load pre-trained weights if provided\n",
    "        if loadweight:\n",
    "            try:\n",
    "                self.loadWeights(loadweight)\n",
    "            except Exception as e:\n",
    "                print(f\"Missing weight file\")\n",
    "\n",
    "        # Make predictions using the model\n",
    "        output = self.model({'query': left_features, 'context': right_features})\n",
    "        output = tf.argmax(output, axis=1).numpy()\n",
    "\n",
    "        # Display prediction results\n",
    "        print(f\"Predicted values (30 samples): {output[:30]}\")\n",
    "        print(f\"Actual labels (30 samples): {y[:30]}\")\n",
    "        print(f\"Overall accuracy: {np.sum(output == y) / len(y)}\")\n",
    "        print(f\"F1 score: {f1_score(y, output, average='weighted')}\")\n",
    "        print(f\"Mean absolute error: {mean_absolute_error(y, output)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530a844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 08:04:21.322391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-10 08:04:21.351851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-10 08:04:21.352102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-10 08:04:21.353481: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-10 08:04:21.354236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-10 08:04:21.354564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-10 08:04:21.354799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-10 08:04:22.318234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-10 08:04:22.318447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-10 08:04:22.318601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-10 08:04:22.318762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2578 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 3s 84ms/step - loss: 3.6886 - accuracy: 0.0281 - val_loss: 3.6893 - val_accuracy: 0.0265\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 3.6891 - accuracy: 0.0242 - val_loss: 3.6893 - val_accuracy: 0.0255\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 3.6896 - accuracy: 0.0258 - val_loss: 3.6893 - val_accuracy: 0.0265\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 3.6883 - accuracy: 0.0242 - val_loss: 3.6893 - val_accuracy: 0.0260\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 3.6893 - accuracy: 0.0258 - val_loss: 3.6893 - val_accuracy: 0.0260\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 3.6893 - accuracy: 0.0250 - val_loss: 3.6892 - val_accuracy: 0.0255\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 3.6882 - accuracy: 0.0215 - val_loss: 3.6892 - val_accuracy: 0.0255\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 3.6891 - accuracy: 0.0250 - val_loss: 3.6892 - val_accuracy: 0.0255\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 3.6892 - accuracy: 0.0242 - val_loss: 3.6892 - val_accuracy: 0.0255\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 3.6882 - accuracy: 0.0270 - val_loss: 3.6892 - val_accuracy: 0.0255\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 3.6889 - accuracy: 0.0219 - val_loss: 3.6892 - val_accuracy: 0.0255\n",
      "/home/jireh/MT/video_sync_v1/trash/featureData.npy\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 3.6891 - accuracy: 0.0250\n",
      "Predicted values (30 samples): [30  7  7 30 30 30 30 30  7 30 30 34 30 30 30 33 30 30  7 30 30 30 30  7\n",
      " 30 30 30 30 30 30]\n",
      "Actual labels (30 samples): [20, 9, 4, 13, -12, 1, -11, -2, -1, 10, 14, -13, -17, 5, 15, -19, 6, 2, -13, -9, -18, 1, -5, 0, 12, -12, 20, -18, -15, 7]\n",
      "Overall accuracy: 0.0066\n",
      "F1 score: 0.0012637071420341381\n",
      "Mean absolute error: 24.4104\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create an instance of TransformerDelay\n",
    "transformer_delay = TransformerDelay(num_heads=8, dff=128, num_layers=2, hidden_dim=512, num_classes=40, rate=0.01)\n",
    "\n",
    "# Step 2: Train the model\n",
    "transformer_delay.train(\n",
    "    pathSimilarityVectorsArray=\"/home/jireh/MT/video_sync_v1/trash/featureData.npy\", \n",
    "    loadweight=\"\", \n",
    "    model_name=\"my_transformer_model\"\n",
    ")\n",
    "\n",
    "# Step 3: Evaluate the model\n",
    "transformer_delay.evaluate(\n",
    "    pathSimilarityVectorsArray=\"/home/jireh/MT/video_sync_v1/trash/featureData.npy\",\n",
    "    loadweight=\"model/TransformerDelay/weight/my_transformer_model/weights\"  # Load the trained weights\n",
    ")\n",
    "\n",
    "# Step 4: Make predictions\n",
    "transformer_delay.predict(\n",
    "    pathSimilarityVectorsArray=\"/home/jireh/MT/video_sync_v1/trash/featureData.npy\",\n",
    "    loadweight=\"model/TransformerDelay/weight/my_transformer_model/weights\",  # Load the trained weights\n",
    "    visualization=False  # Set to True to enable custom visualization\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad4152d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
